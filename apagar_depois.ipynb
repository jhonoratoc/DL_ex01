{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função `train` é responsável pelo treinamento do modelo ao longo de várias épocas. No início de cada época, o modelo é configurado para o modo de treinamento para ativar funcionalidades específicas, como dropout e normalização em lote, que são úteis durante o treinamento. Em seguida, itera-se sobre os lotes de dados de treinamento, calculando a perda entre as previsões do modelo e os rótulos reais. Essa perda é então retropropagada através do modelo para calcular os gradientes e, posteriormente, os parâmetros do modelo são atualizados com base nesses gradientes, utilizando o otimizador especificado. Isso é feito para todos os lotes de treinamento em cada época. Após o término de uma época, a perda média de treinamento é calculada e registrada, e o modelo é avaliado no conjunto de validação usando a função `evaluate`. A perda de validação é calculada e registrada também. Em seguida, o progresso do treinamento é impresso, exibindo a época atual, a perda média de treinamento e a perda de validação correspondente. Esse processo é repetido para o número especificado de épocas.\n",
    "\n",
    "Já a função `evaluate` é usada para avaliar o modelo no conjunto de validação após cada época de treinamento. O modelo é configurado no modo de avaliação para desativar funcionalidades específicas, como dropout, que são úteis apenas durante o treinamento. Em seguida, itera-se sobre os lotes de dados de validação, passando-os pelo modelo para obter as previsões. A perda entre essas previsões e os rótulos reais é calculada e acumulada. Após percorrer todos os lotes de validação, a média das perdas é calculada e retornada como a perda de validação total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Função de treinamento\n",
    "def train(model, criterion, optimizer, train_loader, val_loader, epochs=100):\n",
    "    # Lista para armazenar as perdas de treinamento e validação ao longo das épocas\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    # Iteração sobre as épocas de treinamento\n",
    "    for epoch in range(epochs):\n",
    "        # Coloca o modelo no modo de treinamento\n",
    "        model.train()\n",
    "        # Inicializa a perda acumulada durante o treinamento desta época\n",
    "        running_loss = 0.0\n",
    "\n",
    "        # Iteração sobre os lotes de treinamento\n",
    "        for inputs, labels in train_loader:\n",
    "            # Zera os gradientes acumulados\n",
    "            optimizer.zero_grad()\n",
    "            # Passa os dados de entrada pelo modelo para obter as previsões\n",
    "            outputs = model(inputs)\n",
    "            # Calcula a perda entre as previsões e os rótulos reais\n",
    "            loss = criterion(outputs, labels.unsqueeze(1))\n",
    "            # Retropropagação: calcula os gradientes da perda em relação aos parâmetros do modelo\n",
    "            loss.backward()\n",
    "            # Atualiza os parâmetros do modelo com base nos gradientes calculados\n",
    "            optimizer.step()\n",
    "            # Acumula a perda atual\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        # Calcula a perda média de treinamento para esta época\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        # Adiciona a perda média de treinamento à lista de perdas de treinamento\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # Avalia o modelo no conjunto de validação\n",
    "        val_loss = evaluate(model, criterion, val_loader)\n",
    "        # Adiciona a perda de validação à lista de perdas de validação\n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "        # Imprime o progresso do treinamento\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    # Retorna as listas de perdas de treinamento e validação\n",
    "    return train_losses, val_losses\n",
    "\n",
    "\n",
    "# Função de avaliação\n",
    "def evaluate(model, criterion, val_loader):\n",
    "    # Coloca o modelo no modo de avaliação\n",
    "    model.eval()\n",
    "    # Inicializa a perda acumulada durante a avaliação\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # Temporariamente desabilita o cálculo do gradiente para economizar memória durante a avaliação\n",
    "    with torch.no_grad():\n",
    "        # Iteração sobre os lotes de validação\n",
    "        for inputs, labels in val_loader:\n",
    "            # Passa os dados de entrada pelo modelo para obter as previsões\n",
    "            outputs = model(inputs)\n",
    "            # Calcula a perda entre as previsões e os rótulos reais\n",
    "            loss = criterion(outputs, labels.unsqueeze(1))\n",
    "            # Acumula a perda atual\n",
    "            running_loss += loss.item()\n",
    "    \n",
    "    # Retorna a média das perdas de validação\n",
    "    return running_loss / len(val_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) (os outros são iguais)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este código faz o seguinte:\n",
    "\n",
    "- Divide os dados em conjuntos de treino, validação e teste usando `train_test_split`.\n",
    "- Converte os dados para tensores do PyTorch.\n",
    "- Define a arquitetura de uma rede neural simples com uma camada oculta usando a classe `PerceptronXOR`.\n",
    "- Instancia o modelo, a função de perda (no caso, Binary Cross-Entropy Loss) e o otimizador (Adam).\n",
    "- Define o tamanho do lote (batch) e cria os DataLoader para os conjuntos de treino e validação.\n",
    "- Treina o modelo usando a função `train` definida em utils, que itera sobre os dados de treino e realiza a retropropagação.\n",
    "- Avalia o modelo nos dados de teste usando a função `evaluate`.\n",
    "- Calcula a acurácia do modelo nos dados de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar as bibliotecas necessárias\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils import train, evaluate  # Supondo que essas funções estejam definidas em um módulo chamado utils\n",
    "\n",
    "# Dividir os dados em conjuntos de treino, validação e teste\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_X, data_y, test_size=0.2, random_state=10)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, random_state=10)\n",
    "\n",
    "# Converter os dados para tensores do PyTorch\n",
    "x_train_tensor = torch.tensor(x_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "x_val_tensor = torch.tensor(x_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.float32)\n",
    "x_test_tensor = torch.tensor(x_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Definir a arquitetura da rede neural\n",
    "class PerceptronXOR(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PerceptronXOR, self).__init__()\n",
    "        # Camada de entrada com 2 neurônios e camada oculta com 4 neurônios\n",
    "        self.fc1 = nn.Linear(2, 4)\n",
    "        # Camada de saída com 1 neurônio\n",
    "        self.fc2 = nn.Linear(4, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Ativação ReLU na camada oculta\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        # Ativação sigmoide na camada de saída para obter probabilidades\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "# Instanciar o modelo da rede neural, função de perda e otimizador\n",
    "model = PerceptronXOR()\n",
    "criterion = nn.BCELoss()  # Binary Cross-Entropy Loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Otimizador Adam com taxa de aprendizado de 0.001\n",
    "\n",
    "# Definir o tamanho do lote (batch) e criar os DataLoader para os conjuntos de treino e validação\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(TensorDataset(x_train_tensor, y_train_tensor), batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(TensorDataset(x_val_tensor, y_val_tensor), batch_size=batch_size)\n",
    "\n",
    "# Treinar o modelo utilizando a função definida em utils.train\n",
    "train_losses, val_losses = train(model, criterion, optimizer, train_loader, val_loader, epochs=100)\n",
    "\n",
    "# Avaliar o modelo nos dados de teste\n",
    "test_loader = DataLoader(TensorDataset(x_test_tensor, y_test_tensor), batch_size=batch_size)\n",
    "test_loss = evaluate(model, criterion, test_loader)\n",
    "print(f\"\\nTest Loss: {test_loss:.4f}\")\n",
    "\n",
    "# Calcular a acurácia do modelo\n",
    "model.eval()  # Mudar para o modo de avaliação\n",
    "with torch.no_grad():  # Desativar o cálculo de gradientes durante a avaliação\n",
    "    outputs = model(x_test_tensor)\n",
    "    predicted = torch.round(outputs)  # Arredondar as saídas para 0 ou 1\n",
    "    accuracy = (predicted == y_test_tensor.unsqueeze(1)).sum().item() / predicted.size(0)  # Calcular a acurácia\n",
    "    print(f\"Acurácia: {accuracy:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
