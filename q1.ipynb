{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_vectors = np.array([\n",
    "    [1, -1, -1, -1, -1, -1, -1, -1],\n",
    "    [-1, 1, -1, -1, -1, -1, -1, -1],\n",
    "    [-1, -1, 1, -1, -1, -1, -1, -1],\n",
    "    [-1, -1, -1, 1, -1, -1, -1, -1],\n",
    "    [-1, -1, -1, -1, 1, -1, -1, -1],\n",
    "    [-1, -1, -1, -1, -1, 1, -1, -1],\n",
    "    [-1, -1, -1, -1, -1, -1, 1, -1],\n",
    "    [-1, -1, -1, -1, -1, -1, -1, 1]\n",
    "], dtype=np.float32)\n",
    "\n",
    "data = []\n",
    "\n",
    "n = 1000\n",
    "for i in range(n):\n",
    "    instance = np.array([random.randint(0,1), random.randint(0,1), random.randint(0,1)])\n",
    "    label = [instance[0]*4 + instance[1]*2 + instance[2]]\n",
    "    noise = np.array([random.uniform(-0.1, 0.1), random.uniform(-0.1, 0.1), random.uniform(-0.1, 0.1)])\n",
    "\n",
    "    data.append(np.concatenate((instance + noise, label)))\n",
    "\n",
    "\n",
    "data = np.array(data, dtype=np.float32)\n",
    "\n",
    "train, test = train_test_split(data, test_size=0.2)\n",
    "train, val = train_test_split(train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CubeVertexesDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = self.data[idx, :3]\n",
    "        y = self.data[idx, 3]\n",
    "        return X, y\n",
    "    \n",
    "train_tensor = torch.tensor(train)\n",
    "val_tensor = torch.tensor(val)\n",
    "test_tensor = torch.tensor(test)\n",
    "\n",
    "train_dataloader = DataLoader(CubeVertexesDataset(train_tensor), batch_size=1024)\n",
    "val_dataloader = DataLoader(CubeVertexesDataset(val_tensor), batch_size=1024)\n",
    "test_dataloader = DataLoader(CubeVertexesDataset(test_tensor), batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rosemblatt(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Rosemblatt, self).__init__()\n",
    "        self.perceptron = nn.Linear(3, 8, dtype=torch.float64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.perceptron(x)\n",
    "        return F.softmax(x, dim=1, dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\"cuda\" if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available()\n",
    "    else \"cpu\")\n",
    "\n",
    "model = Rosemblatt().to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    \n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        y = y.type(torch.LongTensor)\n",
    "\n",
    "        # O vetor de features e o seu label são passados para o device\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # As features são passadas pro modelo, que retorna um valor entre -1 e 1,\n",
    "        # devido à função de ativação softmax, o que vai ser o resultado da classificação\n",
    "        out = model(X)\n",
    "\n",
    "        # O erro é calculado\n",
    "        loss = loss_fn(out, y)\n",
    "\n",
    "        # Backpropagation e atualização dos pesos.\n",
    "        loss.backward()\n",
    "        optimizer.zero_grad()\n",
    "        optimizer.step()\n",
    "\n",
    "        # O erro é exibido a cada 1000.\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly.graph_objects as go\n",
    "# fig = go.Figure(data=[go.Scatter3d(x=X_test[:,0], y=X_test[:,1], z=X_test[:,2], mode='markers', marker=dict(size=3, color=y_pred))])\n",
    "# fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
