{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resposta esperada pra cada padrÃ£o\n",
    "response_vectors = np.array([\n",
    "    [1, -1, -1, -1, -1, -1, -1, -1],\n",
    "    [-1, 1, -1, -1, -1, -1, -1, -1],\n",
    "    [-1, -1, 1, -1, -1, -1, -1, -1],\n",
    "    [-1, -1, -1, 1, -1, -1, -1, -1],\n",
    "    [-1, -1, -1, -1, 1, -1, -1, -1],\n",
    "    [-1, -1, -1, -1, -1, 1, -1, -1],\n",
    "    [-1, -1, -1, -1, -1, -1, 1, -1],\n",
    "    [-1, -1, -1, -1, -1, -1, -1, 1]\n",
    "], dtype=np.float32)\n",
    "\n",
    "def one_hot_encode(x):\n",
    "    return response_vectors[x]\n",
    "\n",
    "def add_noise():\n",
    "    return round(random.randint(0,1) + random.uniform(-0.1, 0.1),4) # adiciona ruÃ­do\n",
    "\n",
    "total_data = 1000\n",
    "data_X = np.zeros((total_data,3), dtype=np.float32)\n",
    "data_y = np.zeros((total_data,8), dtype=np.float32)\n",
    "\n",
    "for i in range(total_data):\n",
    "    val = np.array([add_noise(), add_noise(), add_noise()])\n",
    "    data_X[i] = val\n",
    "\n",
    "    code = np.array([round(val[0]), round(val[1]), round(val[2])])\n",
    "    label = np.array([code[0]*4 + code[1]*2 + code[2]])\n",
    "    data_y[i] = one_hot_encode(label)\n",
    "\n",
    "train_X, val_X = np.split(data_X, 2)\n",
    "train_y, val_y = np.split(data_y, 2)\n",
    "\n",
    "val_X, test_X = np.split(val_X, 2)\n",
    "val_y, test_y = np.split(val_y, 2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constroi_listaPCI(X:np.array, y:np.array, w:np.array) -> tuple:\n",
    "    signs = np.sign(X.dot(w))\n",
    "    predicted_labels = np.argmax(signs, axis=1)\n",
    "    actual_labels = np.argmax(y, axis=1)\n",
    "    incorrect_indices = predicted_labels != actual_labels\n",
    "    PCI = X[incorrect_indices]\n",
    "    PCI_y = y[incorrect_indices]\n",
    "\n",
    "    return PCI, PCI_y\n",
    "\n",
    "def PLA(X:np.array, y:np.array, max_iter=10000) -> np.array:\n",
    "    w = np.zeros((3,8))\n",
    "    listaPCI = X.copy()\n",
    "    label = y.copy()\n",
    "    iter_count = 0\n",
    "    \n",
    "    while len(listaPCI) > 0 and iter_count < max_iter:\n",
    "        i = np.random.randint(len(listaPCI))\n",
    "        x = listaPCI[i]\n",
    "\n",
    "        w += np.outer(x, label[i])\n",
    "\n",
    "        listaPCI, label = constroi_listaPCI(X, y, w)\n",
    "        iter_count += 1\n",
    "    return w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82.39999999999999 %\n"
     ]
    }
   ],
   "source": [
    "w = PLA(train_X, train_y)\n",
    "\n",
    "val_predictions = np.sign(val_X.dot(w))\n",
    "accuracy = np.mean(val_predictions == val_y)\n",
    "print(accuracy * 100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('classification_model.pkl', 'wb') as f:\n",
    "    pickle.dump(w, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
